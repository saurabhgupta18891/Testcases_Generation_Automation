from flask import Flask, jsonify, request
from dotenv import load_dotenv
import json
import os
import openai
from openai import OpenAI
from datetime import datetime, timezone
import requests  # type: ignore
import time
from pymongo import MongoClient
from bson import ObjectId
from urllib.parse import urlparse
import datetime
import logging
from lxml import etree
from chained_api_app import generate_testcases_chained, run_testcases_chained


# Configure logging
logging.basicConfig(filename='error.log', level=logging.ERROR, format='%(asctime)s - %(levelname)s: %(message)s')

app = Flask(__name__)
load_dotenv()

log = logging.getLogger('werkzeug')
log.setLevel(logging.ERROR)

client = MongoClient(os.environ.get("MONGO_DB_HOST"))

db = client["airegression"]
services = db["services"]
environments_collection = db['environments2']
environments_config = db["environments_config"]

def env(tenant_env_name):
    model3 = ""
    model4 = ""
    api_key = ""
    model_claude = ""
    apikey_claude = ""
    env_doc = {}
    try:
        # Define the query and projection
        query = {"environments._id": tenant_env_name}
        projection = {"environments.$": 1}

        # Execute the query
        documents = db["tenants"].find(query, projection)
        for doc in documents:
            env_doc = doc["environments"][0]
            print(env_doc)
        model3 = str(env_doc["model3"])
        model4 = env_doc["model4"]
        api_key = str(env_doc["apiKey"])
        model_claude = str(env_doc["Claude_ModelName"])
        apikey_claude = str(env_doc["Claude_APIKey"])

    except Exception as e:
        # Handle any unexpected errors that may occur during the insertion process
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - Error when loading model and api key: {e}")
        print("An unexpected error when loading model and api key occurred:", e)

    return model3, model4, api_key, model_claude, apikey_claude, env_doc


def insert_one_record_in_mongo(collection_name, document):
    """
    Inserts a single document into a MongoDB collection.

    Parameters:
    - db_name (str): The name of the MongoDB database.
    - collection_name (str): The name of the MongoDB collection.
    - document (dict): The document to be inserted into the collection.

    Returns:
    None
    """
    try:
        # Access the specified collection within the database
        collection = db[collection_name]
        # Insert the provided document into the collection
        collection.insert_one(document)
    except Exception as e:
        # Handle any unexpected errors that may occur during the insertion process
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - Error inserting record into MongoDB: {e}")
        print("An unexpected error when inserting log entry into MongoDB occurred:", e)


# Function to create the log entry
def create_log_entry(model_name, system_message, user_prompt, response_text, input_tokens,
                     output_tokens, timestamp_iso8601, unique_request_id, collection_id, prompt_type):
    """
    Creates a log entry for a chat-based interaction.

    Parameters:
    - model_name (str): The name of the OpenAI model used for the chat.
    - system_message (str): The system message provided in the chat.
    - user_prompt (str): The user's prompt in the chat.
    - response_text (str): The response generated by the OpenAI model.
    - input_tokens (int): The number of tokens in the input.
    - output_tokens (int): The number of tokens in the output.
    - timestamp_iso8601 (str): The timestamp in ISO 8601 format.
    - unique_request_id (str): The unique identifier for the request.
    - collection_id (str): The identifier of the collection.
    - prompt_type (str): The type of prompt used in the chat.

    Returns:
    dict: The log entry containing relevant information about the chat interaction.
    """
    log_entry = {
        "collection_id": collection_id,
        "prompt_type": prompt_type,
        "request_id": unique_request_id,
        "timestamp": timestamp_iso8601,
        "model": model_name,
        "input": {
            "system_message": system_message,
            "user_prompt": user_prompt
        },
        "output": {
            "response_text": response_text,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens
        }
    }

    return log_entry


today_date = datetime.datetime.now().strftime("%Y-%m-%d")


def openai_middleware_chat_json(prompt_str, collection_id, prompt_type, tenant_env_name):
    """
    Generates a chat-based response using OpenAI's Chat API, logs the interaction, and inserts the log into a MongoDB database.

    Parameters:
    - prompt_str (str): The user's input prompt for generating the response.
    - collection_id (str): The identifier of the collection to which the generated response belongs.
    - prompt_type (str): The type of prompt used in the chat.

    Returns:
    str: The generated response from the OpenAI Chat API.
    """

    # Initialize variables to store information
    model_name = ""
    system_message = ""
    user_prompt = ""
    response_text = ""
    input_tokens = ""
    output_tokens = ""
    unique_request_id = ""
    timestamp_iso8601 = ""
    answer = ""

    # token, api_key, model = authenticate_api()
    model3, model4, api_key, model_claude, apikey_claude, env_doc = env(tenant_env_name)
    try:
        # Initialize the OpenAI client with the API key
        client = OpenAI(api_key=api_key)

        # Send a chat-based completions request to the OpenAI API
        response = client.chat.completions.create(
            model=model3,
            messages=[
                {"role": "system", "content": "You are a helpful assistant and replies in json format only."},
                {"role": "user", "content": prompt_str}
            ],
            max_tokens=3500,
            temperature=0,
            response_format={"type": "json_object"}
        )

        # Extract information from the API response
        answer = response.choices[0].message.content
        unix_timestamp = response.created
        timestamp_iso8601 = datetime.datetime.fromtimestamp(unix_timestamp, datetime.timezone.utc).isoformat()
        model_name = response.model
        system_message = "You are a helpful assistant and replies in json format only."
        user_prompt = prompt_str
        response_text = answer
        input_tokens = response.usage.prompt_tokens
        output_tokens = response.usage.total_tokens
        unique_request_id = response.id

    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - Error calling OpenAI API: {e}")
        print("An unexpected error when calling OpenAI API occurred:", e)

    # Create a log entry using the extracted information
    log_entry = create_log_entry(model_name, system_message, user_prompt, response_text, input_tokens,
                                 output_tokens, timestamp_iso8601, unique_request_id, collection_id, prompt_type)

    collection_name = "APIPrompts"
    insert_one_record_in_mongo(collection_name, log_entry)

    # Return the generated answer
    return answer


def openai_middleware_chat(prompt_str, tenant_env_name):
    """
    Generates a response using the OpenAI Chat API based on the provided user prompt.

    Parameters:
    - prompt_str (str): The user's input prompt for generating a response.

    Returns:
    str: The generated response from the OpenAI Chat API.
    """
    answer = ""
    model3, model4, api_key, model_claude, apikey_claude, env_doc = env(tenant_env_name)
    try:
        # Initialize the OpenAI client with the API key
        client = OpenAI(api_key=api_key)

        # Send a chat-based completions request to the OpenAI API
        response = client.chat.completions.create(
            model=model3,
            messages=[
                {"role": "system", "content": "You are a helpful assistant"},
                {"role": "user", "content": prompt_str}
            ],
            max_tokens=3500,
            temperature=0
        )

        # Extract the generated response from the API response
        answer = response.choices[0].message.content
    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - Error calling OpenAI API: {e}")
        print("An unexpected error when calling OpenAI API occurred:", e)

    return answer


def fix_json_string(json_string):
    """
    Fixes a JSON-formatted string by replacing single quotes with double quotes.

    Parameters:
    - json_string (str): The JSON-formatted string to be fixed.

    Returns:
    str: The fixed JSON-formatted string.
    """
    # Replace single quotes with double quotes in the JSON string
    json_string_fixed = json_string.replace("'", "\"")
    return json_string_fixed


@app.route('/healthcheck', methods=['GET'])
def healthcheck():
    return jsonify(status='ok')


# Sample testcase for negative testcases
sample_neg = """[
            {
              "version": "1.0",
              "url": <endpoint>,
              "method": "POST",
              "testId": "TC1",
              "name": "Test Case 1",
              "input": {
                "username": "test@foo.com",
                "password": "Test@123"
              },
              "expectedOutput": {
                "400": {
                    "body": {
                        "status": "error",
                        "message": "Error message indicating the issue."
                    }
                }
              }
            },
            {
                "version": "1.0",
                "url": <endpoint>,
                "method": "POST",
                "testId": "TC2",
                "name": "Test Case 2",
                "input": {
                    "username": "test@foo.com",
                    "password": "Test@123"
                },
                "expectedOutput": {
                    "400": {
                        "body": {
                            "status": "error",
                            "message": "Error message indicating the issue."
                        }
                    }
                }
            }
            ]"""

sample_neg_xml = """[
    {
        "version": "1.0",
        "url": "<endpoint>",
        "method": "POST",
        "testId": "TC1",
        "name": "Test Case 1",
        "input": "<REQUEST><USERNAME>test@foo.com</USERNAME><PASSWORD>Test@123</PASSWORD></REQUEST>",
        "expectedOutput": {
            "400": {
                "body": "<RESPONSE><STATUS>ERROR</STATUS><MESSAGE>Error message indicating the issue.</MESSAGE></RESPONSE>"
            }
        }
    },
    {
        "version": "1.0",
        "url": "<endpoint>",
        "method": "POST",
        "testId": "TC2",
        "name": "Test Case 2",
        "input": "<REQUEST><USERNAME>test@foo.com</USERNAME><PASSWORD>Test@123</PASSWORD></REQUEST>",
        "expectedOutput": {
            "400": {
                "body": "<RESPONSE><STATUS>ERROR</STATUS><MESSAGE>Error message indicating the issue.</MESSAGE></RESPONSE>"
            }
        }
    }
]
"""
# Sample testcase for positive testcases
sample_testcase_pos = """
            {
        "testCases": [
            {
              "version": "1.0",
              "url": <endpoint>,
              "method": "POST",
              "testId": "TCD1",
              "name": "Test Case 1",
              "input": {
                "username": "test@foo.com",
                "password": "Test@123"
              },
              "expectedOutput": {
                "200": {
                    "body": {
                        "status": "success",
                        "message": "success message"
                    }
                }
              }
            },
            {
                "version": "1.0",
                "url": <endpoint>,
                "method": "POST",
                "testId": "TCD2",
                "name": "Test Case 2",
                "input": {
                    "username": "test@foo.com",
                    "password": "Test@123"
                },
                "expectedOutput": {
                    "200": {
                        "body": {
                            "status": "success",
                            "message": "success message"
                        }
                    }
                }
            }
            ]
            }"""

sample_testcase_pos_xml = """
{
    "testCases": [
        {
            "version": "1.0",
            "url": "<endpoint>",
            "method": "POST",
            "testId": "TCD1",
            "name": "Test Case 1",
            "input": "<REQUEST><USERNAME>test@foo.com</USERNAME><PASSWORD>Test@123</PASSWORD></REQUEST>",
            "expectedOutput": {
                "200": {
                    "body": "<RESPONSE><STATUS>success</STATUS><MESSAGE>success message</MESSAGE></RESPONSE>"
                }
            }
        },
        {
            "version": "1.0",
            "url": "<endpoint>",
            "method": "POST",
            "testId": "TCD2",
            "name": "Test Case 2",
            "input": "<REQUEST><USERNAME>test@foo.com</USERNAME><PASSWORD>Test@123</PASSWORD></REQUEST>",
            "expectedOutput": {
                "200": {
                    "body": "<RESPONSE><STATUS>success</STATUS><MESSAGE>success message</MESSAGE></RESPONSE>"
                }
            }
        }
    ]
}
"""

# sample testcase for url testcases
sample_testcase_neg_url = """[{
              "version": "1.0",
              "url": <endpoint>,
              "method": "POST",
              "testId": "TC1",
              "name": "Test Case 1",
              "input": {
                "username": "test@foo.com",
                "password": "Test@123"
              },
              "expectedOutput": {
                "404": {
                    "body": {
                        "status": "error",
                        "message": "Error message indicating the issue."
                    }
                }
              }
            }]"""

sample_testcase_neg_url_xml = """[{
              "version": "1.0",
              "url": <endpoint>,
              "method": "POST",
              "testId": "TC1",
              "name": "Test Case 1",
              "input": "<REQUEST><USERNAME>test@foo.com</USERNAME><PASSWORD>Test@123</PASSWORD></REQUEST>",
            "expectedOutput": {
                "404": {
                    "body": "<RESPONSE><STATUS>error</STATUS><MESSAGE>Error message indicating the issue.</MESSAGE></RESPONSE>"
                }
            }
            }]"""

sample_testcase_neg_headers = """[
            {
              "version": "1.0",
              "url": <endpoint>,
              "method": "POST",
              "headers": {
                        "Content-Type": "application/json",
                        "Authorization": "Bearer YOUR_ACCESS_TOKEN"
                    },
              "testId": "TC1",
              "name": "Test Case 1",
              "input": {
                "username": "test@foo.com",
                "password": "Test@123"
              },
              "expectedOutput": {
                "401": {
                    "body": {
                        "status": "error",
                        "message": "Unauthorized"
                    }
                }
              }
            ]
            """

sample_testcase_neg_headers_xml = """[
            {
              "version": "1.0",
              "url": <endpoint>,
              "method": "POST",
              "headers": {
                        "Content-Type": "application/json",
                        "Authorization": "Bearer YOUR_ACCESS_TOKEN"
                    },
              "testId": "TC1",
              "name": "Test Case 1",
              "input": "<REQUEST><USERNAME>test@foo.com</USERNAME><PASSWORD>Test@123</PASSWORD></REQUEST>",
            "expectedOutput": {
                "401": {
                    "body": "<RESPONSE><STATUS>error</STATUS><MESSAGE>Unauthorised.</MESSAGE></RESPONSE>"
                }
            }
            }]
            """
# checklist dictionary for input parameters

checklist_dict = {
    "datetime": [
        "Invalid dates(e.g 99-99-99,05$05$05)",
        "Out of range dates(e.g 01-01-1800)(based on functional definition)",
        "Null values",
        "Empty values",
        "Non-existent dates(e.g 04-31-2024)",
        "Malformed dates(e.g 4%30%2024)",
        "Future dates(e.g 12-25-2050)(based on functional definition)",
        "Past dates(e.g 01-01-2000)(based on functional definition)"
    ],
    "date": [
        "Invalid dates(e.g 99-99-99,05$05$05)",
        "Out of range dates(e.g 01-01-1800)(based on functional definition)",
        "Null values",
        "Empty values",
        "Non-existent dates(e.g 04-31-2024)",
        "Malformed dates(e.g 4%30%2024)",
        "Future dates(e.g 12-25-2050)(based on functional definition)",
        "Past dates(e.g 01-01-2000)(based on functional definition)"
    ],
    "string (YYYY-MM-DD)": [
        "Invalid dates(e.g 99-99-99,05$05$05)",
        "Out of range dates(e.g 01-01-1800)(based on functional definition)",
        "Null values",
        "Empty values",
        "Non-existent dates(e.g 04-31-2024)",
        "Malformed dates(e.g 4%30%2024)",
        "Future dates(e.g 12-25-2050)(based on functional definition)",
        "Past dates(e.g 01-01-2000)(based on functional definition)"
    ],
    "numeric": [
        "Negative numbers",
        "Decimal numbers",
        "Null or empty values",
        "Alphanumeric values",
        "Values with leading or trailing spaces"
    ],
    "number": [
        "Negative numbers",
        "Decimal numbers",
        "Null or empty values",
        "Alphanumeric values",
        "Values with leading or trailing spaces"
    ],
    "string": [
        "Null or empty values",
        "Special characters",
        "HTML or XML tags",
        "SQL Injection"
    ],
    "boolean": [
        "Null or empty values",
        "Alphanumeric string"
    ]
}


def generate_business_points_testcases(functional_definition, api_definition, sample_testcase, collection_id,
                                       tenant_env_name):
    """
        Generates business-related test cases based on the provided functional definition, API definition, and sample test case format.

        Parameters:
        - functional_definition (str): The functional definition of the API.
        - api_definition (str): The API definition.
        - sample_testcase (str): The format of a sample test case.
        - collection_id (str): The ID of the collection where the test cases will be stored in MongoDB.

        Returns:
        - dict: A dictionary containing the generated business-related test cases.
    """

    # Generate prompt for business points
    prompt_business_points = f"""
        I will give the functional definition and the API definition. 
        For each of the input request parameters come up with 1 important business 
        rule if applicable to check if a input is valid. An example would be 
        Interest rate should be between 1 to 5%. Dont worry about the traditional 
        checks based on data type. I am referring to checks that has business context. 
        It should be actionable with specific mathematical  numbers  
        keep it crisp (12 words or less and only 1 bullet per input parameter). 

        Here is the functional definition: {functional_definition}
        Here is the API Definition: {api_definition}
        """

    # Get business checklist from OpenAI chat
    business_checklist = openai_middleware_chat(prompt_business_points, tenant_env_name)

    # Introduce a delay
    time.sleep(2)

    # Initialize the dictionary to store all test cases
    all_test_cases = {"testCases": []}

    # Set the prompt type for business test cases
    prompt_type = "business"

    # Generate prompt for business test cases
    prompt_business_testcases = f"""I will give the functional definition, API definition and the Test Case Format.
        Use the following checklist to create negative test cases.
        {business_checklist}
        while generating testcases related to date type use following dates for future and past dates related testcases:
        for future date:12-25-2025
        for past date:01-01-2022

        Here is the functional definition: {functional_definition}
        Here is the API Definition: {api_definition}
        Here is the Test Case Format: {sample_testcase}
        please generate the testcase in provided testcase format only.
        while creating the testcases please check sample testcase carefully and if sample testcase use xml string for input and expectedOutput then generate testcases in that format only.
        """

    # Get business test cases from OpenAI chat and store in MongoDB
    business_testcases = openai_middleware_chat_json(prompt_business_testcases, collection_id, prompt_type,
                                                     tenant_env_name)

    # Extract test cases from the response
    business_testcases_list = []
    try:
        business_testcases = json.loads(business_testcases)
        test_cases_key = next(iter(business_testcases), "testCases")
        business_testcases_list = business_testcases.get(test_cases_key, [])
    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred while extracting test cases(business): {e}")
        print("An unexpected error occurred while extracting test cases(business) from the response:", e)
        business_testcases = {"testCases": []}

    # Process and format test cases
    try:
        for index, test_case in enumerate(business_testcases_list, start=1):
            test_case["testId"] = f"TC{index}_business"
            if not test_case.get("name"):
                test_case["name"] = "New Testcase"
            all_test_cases["testCases"].append(test_case)

    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred while processing testcases(business): {e}")
        print("An unexpected error occurred while processing testcases(business) generated:", e)
        all_test_cases = {"testCases": []}

    return all_test_cases


def generate_logical_points_testcases(functional_definition, api_definition, sample_testcase, collection_id,
                                      tenant_env_name):
    """
    Generates logical relationship-based test cases based on the provided functional definition, API definition, and sample test case format.

    Parameters:
    - functional_definition (str): The functional definition of the API.
    - api_definition (str): The API definition.
    - sample_testcase (str): The format of a sample test case.
    - collection_id (str): The ID of the collection where the test cases will be stored in MongoDB.

    Returns:
    - dict: A dictionary containing the generated logical relationship-based test cases.
    """

    # Generate prompt for logical points
    prompt_logical_points = f"""I will give the functional definition and the API definition. 
            For each of the input request parameters come up with 1 important business rule 
            if applicable to check relationship between the input parameters is correct. 
            An example, Income should be 2 times or more than the desired monthly payment.  
            Dont worry about the traditional checks based on data type. I am referring to 
            relationship checks between two input parameters
            that has business context.  It should be actionable  with specific mathematical 
            numbers for comparison. Keep it crisp (12 words or less and only 1 bullet per input parameter). 
            Here is the functional definition: {functional_definition}
            Here is the API Definition: {api_definition}
            """

    # Get logical checklist from OpenAI chat
    logical_checklist = openai_middleware_chat(prompt_logical_points, tenant_env_name)

    # Introduce a delay
    time.sleep(2)

    # Initialize the dictionary to store all test cases
    all_test_cases = {"testCases": []}

    # Set the prompt type for logical test cases
    prompt_type = "logical"

    # Generate prompt for logical test cases
    prompt_logical_testcases = f"""I will give the functional definition, API definition and the Test Case Format.
        Use the following checklist to create negative test cases.
        {logical_checklist}
        while generating testcases related to date type use following dates for future and past dates related testcases:
        for future date:12-25-2025
        for past date:01-01-2022

        Here is the functional definition: {functional_definition}
        Here is the API Definition: {api_definition}
        Here is the Test Case Format: {sample_testcase}
        please generate the testcase in provided testcase format only.
        while creating the testcases please check sample testcase carefully and if sample testcase use xml string for input and expectedOutput then generate testcases in that format only.
        """

    # Get logical test cases from OpenAI chat and store in MongoDB
    logical_testcases = openai_middleware_chat_json(prompt_logical_testcases, collection_id, prompt_type,
                                                    tenant_env_name)

    # Extract test cases from the response
    logical_testcases_list = []
    try:
        logical_testcases = json.loads(logical_testcases)
        test_cases_key = next(iter(logical_testcases), "testCases")
        logical_testcases_list = logical_testcases.get(test_cases_key, [])
    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred extracting test cases(logical): {e}")
        print("An unexpected error occurred while extracting test cases(logical) from the response", e)
        logical_testcases = {"testCases": []}

    # Process and format test cases
    try:
        for index, test_case in enumerate(logical_testcases_list, start=1):
            test_case["testId"] = f"TC{index}_logical"
            if not test_case.get("name"):
                test_case["name"] = "New Testcase"
            all_test_cases["testCases"].append(test_case)

    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred processing test cases(logical): {e}")
        print("An unexpected error occurred:", e)
        all_test_cases = {"testCases": []}

    return all_test_cases


def generate_neg_url_testcases(functional_definition, api_definition, sample_testcase, extracted_input_parameters,
                               collection_id, tenant_env_name):
    """
    Generates negative test cases for scenarios where the endpoint URL is incorrect (404 Not Found error).

    Parameters:
    - functional_definition (str): The functional definition of the API.
    - api_definition (str): The API definition.
    - sample_testcase (str): The format of a sample test case.
    - collection_id (str): The ID of the collection where the test cases will be stored in MongoDB.

    Returns:
    - dict: A dictionary containing the generated negative URL test cases.
    """

    # Generate prompt for negative URL test cases
    prompt_neg_url_testcases = f"""
            I will give the functional definition, API definition and the Test Case Format.
            Create a negative scenario testcase where the end point URL is incorrect.
            only make changes after port number in the url.
            The error message should be 404 Not Found error.
            for the other parameters use the following default values when creating the test cases: {extracted_input_parameters}
            Provide your answer in JSON list form as described in the sample testcase.

            Here is the functional definition: {functional_definition}
            Here is the API Definition: {api_definition}
            Here is the Test Case Format: {sample_testcase}
            while creating the testcases please check sample testcase carefully and if sample testcase use xml string for input and expectedOutput then generate testcases in that format only.

            also provide relevant and meaningful error message in testcase generated.
            """

    # Set the prompt type for negative URL test cases
    prompt_type = "neg_url"

    # Get negative URL test cases from OpenAI chat and store in MongoDB
    neg_url_testcases = openai_middleware_chat_json(prompt_neg_url_testcases, collection_id, prompt_type,
                                                    tenant_env_name)

    try:
        # Parse the response and extract test cases
        neg_url_testcases = json.loads(neg_url_testcases)
        test_cases_key = next(iter(neg_url_testcases), "testCases")
        neg_url_testcase = neg_url_testcases.get(test_cases_key, [])

        # Modify the test ID for each test case
        for index, test_case in enumerate(neg_url_testcase, start=1):
            test_case['testId'] = "TC_neg_url"

        # Create a dictionary with the modified test cases
        testcases = {"testCases": neg_url_testcase}

    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred extracting test cases(neg_url): {e}")
        print("An unexpected error occurred while extracting test cases(neg_url) from the response:", e)
        testcases = {"testCases": []}

    return testcases


def generate_neg_headers_testcases(functional_definition, api_definition, sample_testcase, extracted_input_parameters,
                                   collection_id, tenant_env_name):
    """
    Generates negative test cases for scenarios where the endpoint URL is incorrect (404 Not Found error).

    Parameters:
    - functional_definition (str): The functional definition of the API.
    - api_definition (str): The API definition.
    - sample_testcase (str): The format of a sample test case.
    - collection_id (str): The ID of the collection where the test cases will be stored in MongoDB.

    Returns:
    - dict: A dictionary containing the generated negative URL test cases.
    """

    # Generate prompt for negative URL test cases
    prompt_neg_headers_testcases = f"""
        I will give the functional definition, API definition and the Test Case Format.
        Create a negative scenario testcase where the token passed in headers is incorrect.
        The error message should be 401 Unauthorized.
        for the other input parameters use the following default values when creating the test case: {extracted_input_parameters}
        Provide your answer in JSON list form as described in the sample testcase.

        Here is the functional definition: {functional_definition}
        Here is the API Definition: {api_definition}
        Here is the Test Case Format: {sample_testcase}
        while creating the testcases please check sample testcase carefully and if sample testcase use xml string for input and expectedOutput then generate testcases in that format only.
        """

    # Set the prompt type for negative URL test cases
    prompt_type = "neg_headers"

    # Get negative URL test cases from OpenAI chat and store in MongoDB
    neg_headers_testcases = openai_middleware_chat_json(prompt_neg_headers_testcases, collection_id, prompt_type,
                                                        tenant_env_name)
    # print(neg_headers_testcases)
    try:
        # Parse the response and extract test cases
        neg_headers_testcases = json.loads(neg_headers_testcases)
        test_cases_key = next(iter(neg_headers_testcases), "testCases")
        neg_headers_testcase = neg_headers_testcases.get(test_cases_key, [])

        # Modify the test ID for each test case
        for index, test_case in enumerate(neg_headers_testcase, start=1):
            test_case['testId'] = "TC_neg_headers"

        # Create a dictionary with the modified test cases
        testcases = {"testCases": neg_headers_testcase}

    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred extracting test cases(neg_headers): {e}")
        print("An unexpected error occurred while extracting test cases(neg_headers) from the response:", e)
        testcases = {"testCases": []}

    return testcases


def generate_remove_fields_testcases(functional_definition, api_definition, sample_testcase, extracted_input_parameters,
                                     collection_id, tenant_env_name):
    """
    Generates negative test cases for scenarios where one of the mandatory fields is not passed.

    Parameters:
    - functional_definition (str): The functional definition of the API.
    - api_definition (str): The API definition.
    - sample_testcase (str): The format of a sample test case.
    - collection_id (str): The ID of the collection where the test cases will be stored in MongoDB.

    Returns:
    - dict: A dictionary containing the generated remove fields test cases.
    """

    # Generate prompt for remove fields test cases
    prompt_remove_fields_testcases = f"""
        I will give the functional definition, API definition, and the Test Case Format.
        Create negative scenario test cases where one of the mandatory fields is not passed.
        be careful that do not pass null or empty for mandatory fields just completely remove that field.
        Loop through each of the mandatory parameters and 
        create test cases where in each test case one mandatory parameter is not present.

        for the other parameters use the following default values when creating the test cases: {extracted_input_parameters}

        Here is the functional definition: {functional_definition}
        Here is the API Definition: {api_definition}
        Here is the Test Case Format: {sample_testcase}
        please generate the testcase in provided testcase format only.
        while creating the testcases please check sample testcase carefully and if sample testcase use xml string for input and expectedOutput then generate testcases in that format only.
        also provide relevant and meaningful error message in each testcase generated.
        """

    # Set the prompt type for remove fields test cases
    prompt_type = "remove_fields"

    # Get remove fields test cases from OpenAI chat and store in MongoDB
    remove_fields_testcases = openai_middleware_chat_json(prompt_remove_fields_testcases, collection_id, prompt_type,
                                                          tenant_env_name)

    # Initialize the dictionary to store all test cases
    all_test_cases = {"testCases": []}

    # Extract test cases from the response
    remove_fields_testcases_list = []
    try:
        remove_fields_testcases = json.loads(remove_fields_testcases)
        test_cases_key = next(iter(remove_fields_testcases), "testCases")
        remove_fields_testcases_list = remove_fields_testcases.get(test_cases_key, [])
    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred extracting test cases(remove_fields): {e}")
        print("An unexpected error occurred while extracting test cases(remove_fields) from the response", e)
        remove_fields_testcases = {"testCases": []}

    # Process and format test cases
    try:
        for index, test_case in enumerate(remove_fields_testcases_list, start=1):
            test_case["testId"] = f"TC{index}_remove_fields"
            if not test_case.get("name"):
                test_case["name"] = "New Testcase"
            all_test_cases["testCases"].append(test_case)

    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred processing test cases(remove_fields): {e}")
        print("An unexpected error occurred:", e)
        all_test_cases = {"testCases": []}

    return all_test_cases


def generate_test_cases_neg(functional_definition, api_definition, input_parameters, sample_testcase,
                            extracted_input_parameters,
                            checklist_dict, collection_id, tenant_env_name):
    """
    Generates negative test cases by changing the values for each input parameter using a checklist and other information.

    Parameters:
    - functional_definition (str): The functional definition of the API.
    - api_definition (str): The API definition.
    - input_parameters (dict): A dictionary containing input parameters and their types.
    - sample_testcase (str): The format of a sample test case.
    - checklist_dict (dict): A dictionary containing checklists for different parameter types.
    - collection_id (str): The ID of the collection where the test cases will be stored in MongoDB.

    Returns:
    - dict: A dictionary containing the generated negative test cases.
    """

    # Initialize the dictionary to store all test cases
    all_test_cases = {"testCases": []}

    # Iterate over each input parameter
    for param_name, param_type in input_parameters.items():

        # Get the checklist for the parameter type
        checklist = checklist_dict.get(param_type, [])
        checklist_str = "\n".join(checklist)

        # Generate the prompt for negative test cases
        prompt = f"""
            You are an expert in creating test cases for API scenarios.
            I am providing you the functional requirements, API definition and the sample format the API test cases need to be created.

                            functional definition: {functional_definition}
                            api_definition: {api_definition}
                            Sample Test Case JSON: {sample_testcase}

            Create negative test cases by changing the values for the input parameter {param_name} using the checklist & other information given below.
            {checklist_str}
            In case of date and datetime testcase only generate either past or future date testcase on basis of functional definition.
            for the other parameters use the following default values when creating the test cases: {extracted_input_parameters}
            while creating the testcases please check sample testcase carefully and if sample testcase use xml string for input and expectedOutput then generate testcases in that format only.
            Include any specific constraint that needs to be tested based on any description provided in the functional definition.
            please generate the testcase in provided testcase format only.
            also provide relevant and meaningful error message in each testcase generated.
            """
        prompt_type = "neg_testcases"

        # Execute prompt and get test cases
        generated_test_cases = openai_middleware_chat_json(prompt, collection_id, prompt_type, tenant_env_name)
        generated_test_cases_list = []
        try:
            generated_test_cases = json.loads(generated_test_cases)
            test_cases_key = next(iter(generated_test_cases), "testCases")
            generated_test_cases_list = generated_test_cases.get(test_cases_key, [])
        except Exception as e:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            logging.error(f"{timestamp} - error occurred extracting test cases(neg_testcases): {e}")
            print("An unexpected error occurred while extracting test cases(neg_testcases) from the response:", e)
            generated_test_cases = {"testCases": []}

        # Append the generated test cases to the overall list with unique testId
        try:
            for index, test_case in enumerate(generated_test_cases_list, start=1):
                test_case["testId"] = f"TC{index}_{param_name}"
                if not test_case.get("name"):
                    test_case["name"] = "New Testcase"
                all_test_cases["testCases"].append(test_case)

        except Exception as e:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            logging.error(f"{timestamp} - error occurred processing test cases(neg_testcases): {e}")
            print("An unexpected error occurred:", e)
            all_test_cases = {"testCases": []}

    return all_test_cases


def testdata_test_cases(functional_definition, api_definition, sample, test_data, collection_id, tenant_env_name):
    """
    Generates test cases for API scenarios based on provided test data.

    Parameters:
    - functional_definition (str): The functional definition of the API.
    - api_definition (str): The API definition.
    - sample (str): The format of a sample test case.
    - test_data (str): The test data for generating test cases.
    - collection_id (str): The ID of the collection where the test cases will be stored in MongoDB.

    Returns:
    - str: The generated test cases in JSON list form.
    """

    # Generate prompt for test data test cases
    prompt_str = f"""
        You are an expert in creating test cases for API scenarios.
        Generate test cases for the given API docs using the functional requirements, API definition, and test data given below.
        generate 200 status_code positive testcases only.
        Iterate through each test data entry, generating corresponding test cases.
        Each row or entry of test data should translate into a separate test case.
        If there are 10 rows in the test data, it should generate 10 test cases:
        generate exactly same number of testcases as the  number of rows present in the test data.

        Functional Definition: {functional_definition}
        API Definition: {api_definition}
        Test Data: {test_data}
        Sample Test Case: {sample}

        please generate the testcase in provided testcase format only.
        while creating the testcases please check sample testcase carefully and if sample testcase use xml string for input and expectedOutput then generate testcases in that format only.
        Provide your answer in JSON list form. Reply with only the answer in JSON list and include no other commentary.
    """
    prompt_type = "testdata_positive_testcases"

    # print(prompt_str)
    # print(test_data)

    # Execute prompt and get test cases
    print('Sending prompt to OpenAI')
    generated_test_cases = openai_middleware_chat_json(prompt_str, collection_id, prompt_type, tenant_env_name)
    # print(generated_test_cases)
    print('Received response from OpenAI')
    # answer = fix_json_string(answer)
    # Initialize the dictionary to store all test cases
    all_test_cases = {"testCases": []}

    generated_test_cases_list = []
    try:
        generated_test_cases = json.loads(generated_test_cases)
        # print(generated_test_cases)
        test_cases_key = next(iter(generated_test_cases), "testCases")
        generated_test_cases_list = generated_test_cases.get(test_cases_key, [])
    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred extracting test cases: {e}")
        print("An unexpected error occurred while extracting test cases from the response:", e)
        generated_test_cases = {"testCases": []}

    print(generated_test_cases_list)

    # Append the generated test cases to the overall list with unique testId
    try:
        for index, test_case in enumerate(generated_test_cases_list, start=1):
            # print(test_case)
            test_case["testId"] = f"TCD{index}"
            if not test_case.get("name"):
                test_case["name"] = "New Testcase"
            all_test_cases["testCases"].append(test_case)

        for test_case in all_test_cases["testCases"]:
            modified_test_case = test_case.copy()
            status_code_data = modified_test_case['expectedOutput'].get('200', {})
            if 'body' not in status_code_data:
                modified_test_case['expectedOutput']['200'] = {'body': status_code_data}


    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred processing test cases: {e}")
        print("An unexpected error occurred:", e)
        all_test_cases = {"testCases": []}

    return all_test_cases


def testcase_generation_xml(functional_definition, api_definition, input_parameters, sample_neg_xml,
                            sample_testcase_neg_url_xml, sample_testcase_neg_headers_xml,
                            extracted_input_parameters,
                            checklist_dict, collection_id, test_data, gen_testcase_cond, tenant_env_name):
    merged_testcases = []
    if gen_testcase_cond == 0:
        answer_neg = generate_test_cases_neg(functional_definition, api_definition, input_parameters, sample_neg_xml,
                                             extracted_input_parameters,
                                             checklist_dict, collection_id, tenant_env_name)

        answer_business = generate_business_points_testcases(functional_definition, api_definition, sample_neg_xml,
                                                             collection_id, tenant_env_name)

        answer_logical = generate_logical_points_testcases(functional_definition, api_definition, sample_neg_xml,
                                                           collection_id, tenant_env_name)

        # answer_neg_url = generate_neg_url_testcases(functional_definition, api_definition, sample_testcase_neg_url_xml,
        #                                             extracted_input_parameters, collection_id)

        answer_remove_fields = generate_remove_fields_testcases(functional_definition, api_definition, sample_neg_xml,
                                                                extracted_input_parameters, collection_id,
                                                                tenant_env_name)

        answer_neg_headers = generate_neg_headers_testcases(functional_definition, api_definition,
                                                            sample_testcase_neg_headers_xml, extracted_input_parameters,
                                                            collection_id, tenant_env_name)

        # Initialize lists to store test cases of different types
        testcases_list1 = answer_neg.get('testcases', answer_neg.get('testCases', []))
        testcases_list2 = answer_business.get('testcases', answer_business.get('testCases', []))
        testcases_list3 = answer_logical.get('testcases', answer_logical.get('testCases', []))
        # testcases_list4 = answer_neg_url.get('testcases', answer_neg_url.get('testCases', []))
        testcases_list5 = answer_remove_fields.get('testcases', answer_remove_fields.get('testCases', []))
        testcases_list6 = answer_neg_headers.get('testcases', answer_neg_headers.get('testCases', []))
        print(len(testcases_list6))
        testcases_list7 = []

        # Generate test data test cases if test data is provided
        if test_data:
            answer_testdata = testdata_test_cases(functional_definition, api_definition, sample_testcase_pos_xml,
                                                  test_data,
                                                  collection_id, tenant_env_name)
            try:
                testcases_list7 = answer_testdata.get('testcases', answer_testdata.get('testCases', []))
                print(len(testcases_list7))
            except json.JSONDecodeError as e:
                # Handle JSON decoding error
                timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                logging.error(f"{timestamp} - error occurred while decoding JSON response from OpenAI API: {e}")
                answer_testdata = {"error": f"Failed to decode JSON response from OpenAI API: {str(e)}"}

        # Combine test cases from all lists into a single list
        merged_testcases = testcases_list1 + testcases_list2 + testcases_list3 + testcases_list5 + testcases_list6 + testcases_list7
        print(len(merged_testcases))

    elif gen_testcase_cond == 1:

        # generate positive testcases using testdata
        testcases_list7 = []
        # Generate test data test cases if test data is provided
        if test_data:
            answer_testdata = testdata_test_cases(functional_definition, api_definition, sample_testcase_pos_xml,
                                                  test_data,
                                                  collection_id, tenant_env_name)
            try:
                testcases_list7 = answer_testdata.get('testcases', answer_testdata.get('testCases', []))
                print(len(testcases_list7))
            except json.JSONDecodeError as e:
                # Handle JSON decoding error
                timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                logging.error(f"{timestamp} - error occurred while decoding JSON response from OpenAI API: {e}")
                answer_testdata = {"error": f"Failed to decode JSON response from OpenAI API: {str(e)}"}

        # Combine test cases from all lists into a single list
        merged_testcases = testcases_list7
        print(len(merged_testcases))

    return merged_testcases


def testcase_generation_json(functional_definition, api_definition, input_parameters, sample_neg,
                             sample_testcase_neg_url, sample_testcase_neg_headers,
                             extracted_input_parameters,
                             checklist_dict, collection_id, test_data, gen_testcase_cond, tenant_env_name):
    merged_testcases = []
    if gen_testcase_cond == 0:
        answer_neg = generate_test_cases_neg(functional_definition, api_definition, input_parameters, sample_neg,
                                             extracted_input_parameters,
                                             checklist_dict, collection_id, tenant_env_name)

        answer_business = generate_business_points_testcases(functional_definition, api_definition, sample_neg,
                                                             collection_id, tenant_env_name)

        answer_logical = generate_logical_points_testcases(functional_definition, api_definition, sample_neg,
                                                           collection_id, tenant_env_name)

        # answer_neg_url = generate_neg_url_testcases(functional_definition, api_definition, sample_testcase_neg_url,
        #                                             extracted_input_parameters, collection_id)

        answer_remove_fields = generate_remove_fields_testcases(functional_definition, api_definition, sample_neg,
                                                                extracted_input_parameters, collection_id,
                                                                tenant_env_name)

        answer_neg_headers = generate_neg_headers_testcases(functional_definition, api_definition,
                                                            sample_testcase_neg_headers, extracted_input_parameters,
                                                            collection_id, tenant_env_name)

        # Initialize lists to store test cases of different types
        testcases_list1 = answer_neg.get('testcases', answer_neg.get('testCases', []))
        testcases_list2 = answer_business.get('testcases', answer_business.get('testCases', []))
        testcases_list3 = answer_logical.get('testcases', answer_logical.get('testCases', []))
        # testcases_list4 = answer_neg_url.get('testcases', answer_neg_url.get('testCases', []))
        testcases_list5 = answer_remove_fields.get('testcases', answer_remove_fields.get('testCases', []))
        testcases_list6 = answer_neg_headers.get('testcases', answer_neg_headers.get('testCases', []))
        print(len(testcases_list6))
        testcases_list7 = []

        # Generate test data test cases if test data is provided
        if test_data:
            answer_testdata = testdata_test_cases(functional_definition, api_definition, sample_testcase_pos,
                                                  test_data,
                                                  collection_id, tenant_env_name)
            try:
                testcases_list7 = answer_testdata.get('testcases', answer_testdata.get('testCases', []))
                print(len(testcases_list7))
            except json.JSONDecodeError as e:
                # Handle JSON decoding error
                timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                logging.error(f"{timestamp} - error occurred while decoding JSON response from OpenAI API: {e}")
                answer_testdata = {"error": f"Failed to decode JSON response from OpenAI API: {str(e)}"}

        # Combine test cases from all lists into a single list
        merged_testcases = testcases_list1 + testcases_list2 + testcases_list3 + testcases_list5 + testcases_list6 + testcases_list7
        print(len(merged_testcases))

    elif gen_testcase_cond == 1:

        # generate positive testcases using testdata
        testcases_list7 = []
        # Generate test data test cases if test data is provided
        if test_data:
            answer_testdata = testdata_test_cases(functional_definition, api_definition, sample_testcase_pos, test_data,
                                                  collection_id, tenant_env_name)
            try:
                testcases_list7 = answer_testdata.get('testcases', answer_testdata.get('testCases', []))
                print(len(testcases_list7))
            except json.JSONDecodeError as e:
                # Handle JSON decoding error
                timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                logging.error(f"{timestamp} - error occurred while decoding JSON response from OpenAI API: {e}")
                answer_testdata = {"error": f"Failed to decode JSON response from OpenAI API: {str(e)}"}

        # Combine test cases from all lists into a single list
        merged_testcases = testcases_list7
        print(len(merged_testcases))

    return merged_testcases


def flatten_list(nested_list):
    """Flatten a list of lists into a single list."""
    # print(nested_list)
    flattened = []
    for item in nested_list:
        if isinstance(item, list):
            flattened.extend(flatten_list(item))
        else:
            flattened.append(item)
    return flattened


def compare_json(expected, actual):
    # print(expected)
    # print(actual)
    if isinstance(expected, dict) and isinstance(actual, dict):
        for key in expected:
            if key not in actual or not compare_json(expected[key], actual[key]):
                return False
        return True
    elif isinstance(expected, list) and isinstance(actual, list):
        expected_flattened = flatten_list(expected)
        actual_flattened = flatten_list(actual)
        # print(expected_flattened)
        # print(actual_flattened)
        for item in expected_flattened:
            if not any(compare_json(item, act_item) for act_item in actual_flattened):
                return False
        return True
    else:
        return expected == actual


def run_tests(test_case, url, headers, collection_id, tenant_env_name):
    """
    Executes a test case against a specified API endpoint and evaluates the result.

    Parameters:
    - test_case (dict): Dictionary containing the test case details, including input parameters and expected output.
    - url (str): The URL of the API endpoint to test.

    Returns:
    - dict: A dictionary containing information about the test result, including status code, response time,
            test ID, response size, response content, and the overall result (Passed/Failed).
    """
    parameters = {}

    try:
        parameters = test_case["input"]
        print(f"Executing test case: {test_case['testId']}")
        print(parameters)
    except Exception as e:
        print("An unexpected error occurred:", e)

    status_code = 400
    response_content = ''
    response_size = 0
    response_time = 0
    response = {}

    if "neg_url" in test_case["testId"]:
        url = test_case["url"]

    if "neg_headers" in test_case["testId"]:
        headers = test_case["headers"]

    try:
        if not test_case["method"]:
            test_case["method"] = 'POST'
    except Exception as e:
        print("An unexpected error occurred:", e)
        test_case["method"] = 'POST'

    if test_case["method"] == 'POST':
        start_time = time.time()

        try:
            # Send a POST request to the specified API endpoint with the provided parameters
            response = requests.post(url, json=parameters, headers=headers)
            status_code = response.status_code
            print(status_code)
            response_content = response.json()
            response_size = len(response.text)
        except Exception as e:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            logging.error(f"{timestamp} - error occurred while sending request to api: {e}")
            response = {'error': str(e)}
            error_message = str(e)
            print(error_message)
            error_code = "runtestcases_error"
            log_error_to_db(collection_id, error_code, error_message, tenant_env_name)
            print("An unexpected error occurred while sending request to api:", e)
            return response
            # status_code = 400
            # response_size = 0

        end_time = time.time()
        response_time = end_time - start_time

    elif test_case["method"] == 'GET':
        start_time = time.time()

        try:
            # Send a GET request to the specified API endpoint with the provided parameters
            response = requests.get(url, params=parameters, headers=headers)
            status_code = response.status_code
            print(status_code)
            # response.raise_for_status()
            response_content = response.json()
            response_size = len(response.text)
        # except requests.exceptions.RequestException as e:
        #     print(f"An unexpected error occurred while sending request to api: {e}")
        # status_code = 400
        # response_size = 0
        except Exception as e:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            logging.error(f"{timestamp} - error occurred while sending request to api: {e}")
            response = {'error': str(e)}
            error_message = str(e)
            print(error_message)
            error_code = "runtestcases_error"
            log_error_to_db(collection_id, error_code, error_message, tenant_env_name)
            print("An unexpected error occurred while sending request to api:", e)
            return response
            # status_code = 400
            # response_size = 0

        end_time = time.time()
        response_time = end_time - start_time

    matched = "False"

    # Initialize the result dictionary
    result = {
        "statusCode": status_code,
        "responseTime": response_time,
        "testId": test_case['testId'],
        "name": test_case['name'],
        "version": test_case.get('version', 1),
        "response_size": response_size,
        "responseContent": response_content,
        "input": test_case["input"],
        "expectedOutput": test_case["expectedOutput"],
        "responseHeader": headers,
        "result": ""
    }

    # print(result)

    try:
        # Check if the test ID indicates a detailed comparison (contains 'TCD' or 'tcd')
        if 'TCD' in test_case['testId'] or 'tcd' in test_case['testId']:
            expected_output_body = test_case['expectedOutput'].get('200', {}).get('body', {})

            # Match JSON structure and fields data
            if compare_json(expected_output_body, response_content):
                matched = "True"
        else:
            # If the test ID does not contain 'TCD' or 'tcd', only compare the status code
            expected_status_code_str = list(test_case["expectedOutput"].keys())[0]

            # Check if the expected status code is a string containing only digits
            if expected_status_code_str.isdigit():
                expected_status_code = int(expected_status_code_str)
                if status_code == expected_status_code:
                    matched = "True"
            else:
                # Handle the case where the expected status code is not a valid integer
                expected_status_code = expected_status_code_str
                if status_code == expected_status_code:
                    matched = "True"

        # Update the result dictionary based on the matched value
        result["result"] = "Passed" if matched == "True" else "Failed"

    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred while comparing the status_codes and fields: {e}")
        print("An unexpected error occurred while comparing the status_codes and fields:", e)
        result["result"] = "Failed"

    # print(result)

    return result


def compare_xmls(expected_xml_str, actual_xml_str):
    # Convert the input strings to bytes (necessary for handling encoding declarations)
    expected_bytes = expected_xml_str.encode('utf-8')
    actual_bytes = actual_xml_str.encode('utf-8')

    try:
        # Parse the XML strings into XML trees
        expected_tree = etree.fromstring(expected_bytes)
        actual_tree = etree.fromstring(actual_bytes)

        # Convert the trees back into canonical XML strings
        expected_canonical = etree.tostring(expected_tree, method="c14n").decode('utf-8')
        actual_canonical = etree.tostring(actual_tree, method="c14n").decode('utf-8')

        # Compare canonical XML strings
        if expected_canonical == actual_canonical:
            print("XMLs match!")
            return True
        else:
            print("XMLs do not match!")
            # print("Expected XML:", expected_canonical)
            # print("Actual XML:", actual_canonical)
            return False
    except etree.XMLSyntaxError as e:
        print(f"XML parsing error: {e}")
        return False


def run_tests_xml(test_case, url, headers, xml_input_field, collection_id, tenant_env_name):
    """
    Executes a test case against a specified API endpoint and evaluates the result for XML-based APIs.

    Parameters:
    - test_case (dict): Dictionary containing the test case details, including input parameters and expected output.
    - url (str): The URL of the API endpoint to test.

    Returns:
    - dict: A dictionary containing information about the test result, including status code, response time,
            test ID, response size, response content, and the overall result (Passed/Failed).
    """
    input_data = ""

    try:
        input_data = test_case["input"]
        print(f"Executing test case: {test_case['testId']}")
        print(input_data)
    except Exception as e:
        print("An unexpected error occurred:", e)

    data = ""
    try:
        if len(xml_input_field) != 0:
            data = {xml_input_field: input_data}
            print(data)
        else:
            data = input_data
    except Exception as e:
        print("An unexpected error occurred:", e)
    print(data)

    # Prepare headers (assuming it's XML, but can be made dynamic if needed)
    # headers = {
    #     "Content-Type": "application/x-www-form-urlencoded",
    #     "accessTokenKey": "dHRpY3Jtc2FuZGJveA=="  # Sample accessTokenKey, can be dynamic too
    # }

    status_code = 400
    actual_body = ''
    response_size = 0
    response_time = 0
    response = {}

    if "neg_url" in test_case["testId"]:
        url = test_case["url"]

    if "neg_headers" in test_case["testId"]:
        headers = test_case["headers"]

    try:
        if not test_case["method"]:
            test_case["method"] = 'POST'
    except Exception as e:
        print("An unexpected error occurred:", e)
        test_case["method"] = 'POST'

    if test_case["method"] == 'POST':
        start_time = time.time()

        try:
            # Send a POST request to the specified API endpoint with the provided parameters
            response = requests.post(url, headers=headers, data=data)
            status_code = response.status_code
            print(status_code)
            actual_body = response.text
            response_size = len(response.text)
        except Exception as e:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            logging.error(f"{timestamp} - error occurred while sending request to api: {e}")
            response = {'error': str(e)}
            error_message = str(e)
            print(error_message)
            error_code = "runtestcases_error"
            log_error_to_db(collection_id, error_code, error_message, tenant_env_name)
            print("An unexpected error occurred while sending request to api:", e)
            return response
            # status_code = 400
            # response_size = 0

        end_time = time.time()
        response_time = end_time - start_time

    elif test_case["method"] == 'GET':
        start_time = time.time()

        try:
            # Send a GET request to the specified API endpoint with the provided parameters
            response = requests.get(url, headers=headers, params=data)
            status_code = response.status_code
            print(status_code)
            # response.raise_for_status()
            actual_body = response.text
            response_size = len(response.text)
        # except requests.exceptions.RequestException as e:
        #     print(f"An unexpected error occurred while sending request to api: {e}")
        # status_code = 400
        # response_size = 0
        except Exception as e:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            logging.error(f"{timestamp} - error occurred while sending request to api: {e}")
            response = {'error': str(e)}
            error_message = str(e)
            print(error_message)
            error_code = "runtestcases_error"
            log_error_to_db(collection_id, error_code, error_message, tenant_env_name)
            print("An unexpected error occurred while sending request to api:", e)
            return response
            # status_code = 400
            # response_size = 0

        end_time = time.time()
        response_time = end_time - start_time

    matched = "False"

    # Initialize the result dictionary
    result = {
        "statusCode": status_code,
        "responseTime": response_time,
        "testId": test_case['testId'],
        "name": test_case['name'],
        "version": test_case.get('version', 1),
        "response_size": response_size,
        "responseContent": actual_body,
        "input": test_case["input"],
        "expectedOutput": test_case["expectedOutput"],
        "responseHeader": headers,
        "result": ""
    }

    # print(result)

    try:
        # Check if the test ID indicates a detailed comparison (contains 'TCD' or 'tcd')
        if 'TCD' in test_case['testId'] or 'tcd' in test_case['testId']:
            expected_output_body = test_case['expectedOutput'].get('200', {}).get('body', {})

            # Match JSON structure and fields data
            if compare_xmls(expected_output_body, actual_body):
                matched = "True"
        else:
            # If the test ID does not contain 'TCD' or 'tcd', only compare the status code
            expected_status_code_str = list(test_case["expectedOutput"].keys())[0]

            # Check if the expected status code is a string containing only digits
            if expected_status_code_str.isdigit():
                expected_status_code = int(expected_status_code_str)
                if status_code == expected_status_code:
                    matched = "True"
            else:
                # Handle the case where the expected status code is not a valid integer
                expected_status_code = expected_status_code_str
                if status_code == expected_status_code:
                    matched = "True"

        # Update the result dictionary based on the matched value
        result["result"] = "Passed" if matched == "True" else "Failed"

    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred while comparing the status_codes and fields: {e}")
        print("An unexpected error occurred while comparing the status_codes and fields:", e)
        result["result"] = "Failed"

    return result


def log_error_to_db(collection_id, error_code, error_message, tenant_env_name):
    try:
        record = {
            'collectionId': collection_id,
            'createdAt': datetime.datetime.now(timezone.utc),
            'failedReason': {"code": error_code, "message": error_message},
            'results': [],
            'status': 'Failed',
            'selectedEnvId': tenant_env_name
        }
        db["apitestresults"].insert_one(record)

        # updating intermediate data
        print("Updating Intermediate Data for Stats Calculation during error log!!!")
        update_intermediate_data(child_dict=record)
        print("Data updation done!!!")

    except Exception as e:
        logging.error(f"Error inserting failed reason into apitestresults: {e}")


def authenticate_api(collection_id, tenant_env_name):
    # Fetch the latest environment config document
    latest_environment_config_doc = {}
    try:
        latest_environment_config_doc = environments_config.find_one({}, sort=[('_id', -1)])
        # print(latest_environment_config_doc)
        if not latest_environment_config_doc:
            error_message = "No documents found in environments_config"
            logging.error(error_message)
            # log_error_to_db(collection_id, "NO_DOCUMENT", error_message)
    except Exception as e:
        error_message = f"Error fetching document from environments_config: {e}"
        logging.error(error_message)
        # log_error_to_db(collection_id, "FETCH_ERROR", error_message)

    # Retrieve metadata and credentials
    metadata = latest_environment_config_doc.get('credentialFieldMapper', {})
    userid_fieldname = metadata.get('userIDFieldName')
    password_fieldname = metadata.get('passwordFieldName')
    token_fieldname = metadata.get('tokenFieldName')
    api_glide = latest_environment_config_doc.get('apiGlide', {})
    error_fieldname = api_glide.get('errorFieldName')

    if not userid_fieldname:
        error_message = "userid_fieldname not found."
        logging.error(error_message)
        log_error_to_db(collection_id, "Authentication parameters are not present", error_message, tenant_env_name)
        return {"error": error_message}

    if not password_fieldname:
        error_message = "password_fieldname not found."
        logging.error(error_message)
        log_error_to_db(collection_id, "Authentication parameters are not present", error_message, tenant_env_name)
        return {"error": error_message}

    if not token_fieldname:
        error_message = "token_fieldname not found."
        logging.error(error_message)
        log_error_to_db(collection_id, "Authentication parameters are not present", error_message, tenant_env_name)
        return {"error": error_message}

    if not error_fieldname:
        error_message = "error_fieldname not found."
        logging.error(error_message)
        log_error_to_db(collection_id, "Authentication parameters are not present", error_message, tenant_env_name)
        return {"error": error_message}


    model3, model4, api_key, model_claude, apikey_claude, env_doc = env(tenant_env_name)
    api_authentication_url = str(env_doc["authenticationURL"])
    uid = env_doc.get(userid_fieldname)
    password = env_doc.get(password_fieldname)
    # tenant_key = env_doc.get("TenantKey")

    # Validate API authentication URL
    if not api_authentication_url:
        error_message = "API authentication URL not found."
        logging.error(error_message)
        log_error_to_db(collection_id, "MISSING_URL", error_message, tenant_env_name)
        return {"error": error_message}

    # Validate user ID and password
    if not uid or not password:
        error_message = "User ID or password is empty."
        logging.error(error_message)
        log_error_to_db(collection_id, "MISSING_CREDENTIALS", error_message, tenant_env_name)
        return {"error": error_message}

    auth_payload = {}

    api_auth = api_glide.get('apiAuthentication')
    use_Auth_parameters = api_auth.get('useAuthParameters')

    if use_Auth_parameters == True:
        grant_type = api_auth["grantType"]["value"]
        client_id = api_auth["clientId"]["value"]
        client_secret = api_auth["clientSecret"]["value"]

        grant_type_type = api_auth["grantType"]["type"]
        client_id_type = api_auth["clientId"]["type"]
        client_secret_type = api_auth["clientSecret"]["type"]

        if grant_type_type == "request" and client_id_type == "request" and client_secret_type == "request":
            auth_payload = {userid_fieldname: uid, password_fieldname: password,
                            'grant_type': grant_type, 'client_id': client_id,
                            'client_secret': client_secret}
            # print(auth_payload)
    else:
        auth_payload = {userid_fieldname: uid, password_fieldname: password}

    print(auth_payload)

    # Send authentication request
    status_code = 400
    response = {}
    try:
        response = requests.post(api_authentication_url, json=auth_payload)
        status_code = response.status_code
        print(status_code)
        logging.info(f"Status code after sending request to authentication URL: {status_code}")
    except Exception as e:
        error_message = f"Error sending request to authentication URL: {e}"
        error_message1 = "Invalid Authentication Host"
        logging.error(error_message)
        log_error_to_db(collection_id, "REQUEST_ERROR", error_message1, tenant_env_name)
        return {"error": error_message}

    error_message = ""
    APITenantKeyFieldName = ""
    tenant_key = ""
    # Process response
    if status_code == 200:
        data = response.json()
        token_value = data.get(token_fieldname)
        print(token_value)
        # expiration_time = data.get('expiration_time')
        # if expiration_time:
        #     expiration_time = datetime.datetime.strptime(expiration_time, "%a, %d %b %Y %H:%M:%S %Z")

        api_tenantkey = api_glide.get('apiTenantKey')

        if api_tenantkey["useAuthParameters"] == True:
            if api_tenantkey["apiTenantKeyFieldName"]["type"] == "header":
                APITenantKeyFieldName = api_tenantkey["apiTenantKeyFieldName"]["value"]
                tenant_key = env_doc["TenantKey"]
                print(tenant_key)
                return {"token": token_value, "tenant_key_fieldname": APITenantKeyFieldName, "tenantkey": tenant_key}
            else:
                error_message = "tenantkey should be passed in headers"
                log_error_to_db(collection_id, "AUTHENTICATION_FAILED", error_message, tenant_env_name)
                return {"error": error_message}

        return {"token": token_value}

    elif status_code == 400:
        try:
            data = response.json()
            error_message = data.get(error_fieldname, "")
            log_error_to_db(collection_id, "AUTHENTICATION_FAILED", error_message, tenant_env_name)
            logging.error(f"Authentication failed:")
            return {"error": error_message}
        except Exception as e:
            error_message = "Authentication Failed"
            # log_error_to_db(collection_id, "AUTHENTICATION_FAILED", error_message)

            return {"error": error_message}
    elif status_code == 404:
        error_message = "Invalid Authentication URL"
        log_error_to_db(collection_id, "AUTHENTICATION_FAILED", error_message, tenant_env_name)
        return {"error": error_message}


@app.route('/v1/generate_testcases', methods=['POST'])
def generate_testcases():
    # Extract data from the incoming JSON request
    data = request.get_json()
    collection_id = data.get('collection_id', '')

    # Connect to MongoDB and retrieve the collection data
    db = client["airegression"]
    collections = db["collections"]

    try:
        cursor = collections.find({"_id": ObjectId(collection_id)})
        doc = 0
        for document in cursor:
            doc = document
        print(doc)

    except Exception as e:
        print("An unexpected error occurred while fetching the doc in mongo collection:", e)
        doc = {}

    # Extract functional definition and API definition from the retrieved document
    try:
        functional_definition = f"""{doc['functionalRequirements']}"""
        api_definition = f"""{doc['apiDefinition']}"""
    except Exception as e:
        print("An unexpected error occurred while extracting funct_def and api_def from doc:", e)
        functional_definition = """ """
        api_definition = """ """

    # Extract test data from the retrieved document
    test_data = {}
    if doc['testDataId'] != None and len(doc['testDataId']) > 0:
        testdataTable = db['apiglide']
        cursor = testdataTable.find({"_id": ObjectId(doc['testDataId'])})
        testdata_doc = 0
        for document in cursor:
            testdata_doc = document
        if testdata_doc != 0:
            test_data = testdata_doc['testdata']
            print("testdata",test_data)

    # parsed_data = json.loads(data)
    test_data_first_row = {}
    try:
        if test_data:
            # Extract the first record regardless of the key name
            # first_record_key, first_record_value = next(iter(test_data.items()))
            # test_data_first_row = first_record_value
            test_data_first_row = test_data["row_id_1"]
            print("testdata_first_row",test_data_first_row)
    except Exception as e:
        print("error occurred while extracting first row of testdata")
        test_data_first_row = {}

    print(test_data_first_row)

    # Create a dictionary to store extracted parameters
    input_parameters = {}
    api_definition_data = {}
    api_url = ""

    try:
        try:
            # Attempt to parse the JSON string
            api_definition_data = json.loads(api_definition)
        except json.JSONDecodeError as e:
            print("Invalid JSON syntax:", e)
            logging.error(f"error occurred while parsing api_def json string: {e}")
            # Handle the exception (e.g., remove line breaks and retry parsing)
            # Here's a simple example of removing line breaks:
            cleaned_api_definition = api_definition.replace("\n", "")
            try:
                # Retry parsing with cleaned JSON string
                api_definition_data = json.loads(cleaned_api_definition)
            except json.JSONDecodeError as e:
                print("Unable to parse JSON even after cleaning the api_def json string:", e)
        # Extract request parameters
        request_parameters = api_definition_data.get("requestParameters", [])
        print(request_parameters)
        # Iterate through request parameters and extract name and type
        for parameter in request_parameters:
            name = parameter.get("name")
            parameter_type = parameter.get("type")

            # Save extracted parameters in the dictionary
            input_parameters[name] = parameter_type

        # print(input_parameters)

    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred while extracting input parameters from api_def: {e}")
        print("An unexpected error occurred while extracting input parameters from api_def:", e)
        input_parameters = {}

    def extract_input_parameters(api_definition_data, test_data_first_row):
        # Extract parameter names from the API definition
        parameter_names = [param['name'] for param in api_definition_data.get('requestParameters', [])]

        # Filter out only the relevant parameters from the input JSON
        extracted_input_parameters = {param: test_data_first_row.get(param) for param in parameter_names}

        return extracted_input_parameters

    # Extract input parameters
    extracted_input_parameters = extract_input_parameters(api_definition_data, test_data_first_row)

    print("extracted_input_parameters:",extracted_input_parameters)

    try:
        # Extract the API endpoint URL
        api_url = api_definition_data["endpoint"]
        print(api_url)

    except Exception as e:
        print("An unexpected error occurred while extracting url from api_def:", e)
        api_url = ""

    merged_testcases = []

    try:
        gen_testcase_cond = doc["createtestdatacasesonly"]
        api_datatype = doc["apiDataType"]
    except:
        gen_testcase_cond = 0
        api_datatype = "JSON"

    tenant_env_name = data.get("selectedEnvId")
    print(tenant_env_name)
    if not tenant_env_name:
        tenant_env_name = "324234324"

    if api_datatype.lower() == "xml":

        # Generate both positive and negative testcases
        # Generate various types of test cases using OpenAI API
        merged_testcases = testcase_generation_xml(functional_definition, api_definition, input_parameters,
                                                   sample_neg_xml, sample_testcase_neg_url_xml,
                                                   sample_testcase_neg_headers_xml,
                                                   extracted_input_parameters,
                                                   checklist_dict, collection_id, test_data, gen_testcase_cond,
                                                   tenant_env_name)

    else:
        merged_testcases = testcase_generation_json(functional_definition, api_definition, input_parameters, sample_neg,
                                                    sample_testcase_neg_url, sample_testcase_neg_headers,
                                                    extracted_input_parameters,
                                                    checklist_dict, collection_id, test_data, gen_testcase_cond,
                                                    tenant_env_name)

    # Update MongoDB with the generated test cases and endpoint URL
    status = False
    try:
        collections.update_one({"_id": ObjectId(collection_id)}, {
            '$set': {
                "endpoint": api_url,
                "testcases": merged_testcases,
                'status': 'TEST_CASES_GENERATED',
                'updatedAt': datetime.datetime.now()
            }
        })
        status = True
    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred while updating the collection with testcases: {e}")
        print("An unexpected error occurred while updating the collection with testcases:", e)
        collections.update_one({"_id": ObjectId(collection_id)}, {
            '$set': {
                "status": 'TEST_CASES_GENERATION_FAILED',
                'updatedAt': datetime.datetime.now()
            }
        })

    return {
        'status': status
    }


def authentication(collection_id, tenant_env_name):
    # Fetch the latest environment config document
    latest_environment_config_doc = {}
    try:
        latest_environment_config_doc = environments_config.find_one({}, sort=[('_id', -1)])
        # print(latest_environment_config_doc)
        if not latest_environment_config_doc:
            error_message = "No documents found in environments_config"
            logging.error(error_message)
            # log_error_to_db(collection_id, "NO_DOCUMENT", error_message)
    except Exception as e:
        error_message = f"Error fetching document from environments_config: {e}"
        logging.error(error_message)

    api_glide = latest_environment_config_doc.get('apiGlide', {})
    api_Authentication_Type = api_glide.get('apiAuthenticationType', '')
    content_type = api_glide.get('apiContentType', '')
    content_type = content_type.lower()
    token_type = api_glide.get('apiTokenType', '')
    # Retrieve metadata and credentials
    metadata = latest_environment_config_doc.get('credentialFieldMapper', {})
    token_fieldname = metadata.get('tokenFieldName', '')

    headers = {}
    if api_Authentication_Type.lower() == "static":
        access_token_value = api_glide.get('apiAccessTokenValue', '')
        if content_type == "json":
            headers = {
                token_fieldname: access_token_value,
                'Content-Type': 'application/json',
            }
        if content_type == "xml":
            headers = {
                token_fieldname: access_token_value,
                'Content-Type': 'application/xml',
            }
        if content_type == "form-url_encoded":
            headers = {
                token_fieldname: access_token_value,
                'Content-Type': 'application/x-www-form-urlencoded',
            }

    if api_Authentication_Type.lower() == "basicauthentication":

        # Call the authentication method
        auth_res = authenticate_api(collection_id, tenant_env_name)
        # Create header with token
        if "token" in auth_res:
            token_value = auth_res["token"]

            if token_type.lower() == "bearertoken":

                if "tenant_key_fieldname" in auth_res and "tenantkey" in auth_res:

                    tenant_key_fieldname = auth_res["tenant_key_fieldname"]
                    tenantkey = auth_res["tenantkey"]
                    print(tenant_key_fieldname)
                    print(tenantkey)
                    if content_type == "json":
                        headers = {
                            'Authorization': f'Bearer {token_value}',
                            'Content-Type': 'application/json',
                            tenant_key_fieldname: tenantkey
                        }
                    if content_type == "xml":
                        headers = {
                            'Authorization': f'Bearer {token_value}',
                            'Content-Type': 'application/xml',
                            tenant_key_fieldname: tenantkey
                        }
                    if content_type == "form-url_encoded":
                        headers = {
                            'Authorization': f'Bearer {token_value}',
                            'Content-Type': 'application/x-www-form-urlencoded',
                            tenant_key_fieldname: tenantkey
                        }

                else:
                    if content_type == "json":
                        headers = {
                            'Authorization': f'Bearer {token_value}',
                            'Content-Type': 'application/json',
                        }
                    if content_type == "xml":
                        headers = {
                            'Authorization': f'Bearer {token_value}',
                            'Content-Type': 'application/xml',
                        }
                    if content_type == "form-url_encoded":
                        headers = {
                            'Authorization': f'Bearer {token_value}',
                            'Content-Type': 'application/x-www-form-urlencoded',
                        }

            if token_type.lower() == "apikey":

                if "tenant_key_fieldname" in auth_res and "tenantkey" in auth_res:

                    tenant_key_fieldname = auth_res["tenant_key_fieldname"]
                    tenantkey = auth_res["tenantkey"]
                    print(tenant_key_fieldname)
                    print(tenantkey)
                    if content_type == "json":
                        headers = {
                            token_fieldname: token_value,
                            'Content-Type': 'application/json',
                            tenant_key_fieldname: tenantkey
                        }
                    if content_type == "xml":
                        headers = {
                            token_fieldname: token_value,
                            'Content-Type': 'application/xml',
                            tenant_key_fieldname: tenantkey
                        }
                    if content_type == "form-url_encoded":
                        headers = {
                            token_fieldname: token_value,
                            'Content-Type': 'application/x-www-form-urlencoded',
                            tenant_key_fieldname: tenantkey
                        }

                else:
                    if content_type == "json":
                        headers = {
                            token_fieldname: token_value,
                            'Content-Type': 'application/json',
                        }
                    if content_type == "xml":
                        headers = {
                            token_fieldname: token_value,
                            'Content-Type': 'application/xml',
                        }
                    if content_type == "form-url_encoded":
                        headers = {
                            token_fieldname: token_value,
                            'Content-Type': 'application/x-www-form-urlencoded',
                        }
        elif "error" in auth_res:
            return auth_res


    xml_input_field = api_glide.get('apiXmlInputFieldName', '')
    if xml_input_field and len(xml_input_field) != 0:
        return {"headers": headers, "xml_input_field": xml_input_field}

    return {"headers": headers, "xml_input_field": ''}


@app.route("/v1/run_testcases", methods=['GET', "POST"])
def run_testcases():
    print('Test Execution started......')

    # Extract data from the incoming JSON request
    data = request.get_json()
    collection_id = data.get('collection_id', '')
    tenant_env_name = data.get("selectedEnvId")
    print("env_id:",tenant_env_name)
    if not tenant_env_name:
        tenant_env_name = "a92935d3"

    source = data.get('source', '')
    source_Id = data.get('sourceId', '')

    # Connect to MongoDB and retrieve the collection data
    db = client["airegression"]
    collections = db["collections"]

    # Call the authentication method
    auth_res = authentication(collection_id, tenant_env_name)
    if "headers" in auth_res:
        headers = auth_res["headers"]
        print(headers)
        xml_input_field = auth_res["xml_input_field"]
        print(xml_input_field)
        # Create header with token
        # failedReason = ""

        # print(collection_id)
        # Initialize variables to store collection details and test results
        collection_doc = {}
        results = []

        try:
            # Retrieve collection details from MongoDB using the provided collection_id
            cursor = collections.find({"_id": ObjectId(collection_id)})
            for document in cursor:
                collection_doc = document

        except Exception as e:
            print("An unexpected error occurred while loading doc from collection:", e)
            collection_doc = {}
        try:
            api_datatype = collection_doc["apiDataType"]
        except:
            api_datatype = "JSON"
        new_endpoint = ""
        failedReason = ""
        env_doc = {}
        try:
            # Extract the API endpoint URL from the collection document
            url_endpoint = collection_doc["endpoint"]
            print(url_endpoint)

            model3, model4, api_key, model_claude, apikey_claude, env_doc = env(tenant_env_name)
            # print(env_doc)
            if env_doc:
                url_host = env_doc.get("apiHost", "")
                print(url_host)
                if url_host:
                    # Parse the endpoint URL
                    parsed_url = urlparse(url_endpoint)

                    # Extract the path after the port number
                    path_after_port = parsed_url.path

                    # Construct a new endpoint URL with a predefined base URL
                    new_endpoint = url_host + path_after_port
                    print("new_endpoint:", new_endpoint)
                else:
                    failedReason = "run testcases failed:apiHost not found"
                    # print(new_endpoint)
            else:
                failedReason = "run testcases failed:doc related to the env not found"
        except Exception as e:
            print("An unexpected error occurred while getting url from doc:", e)
            new_endpoint = ""

        if failedReason == "":

            status = ""
            try:
                # Iterate through test cases in the collection document and execute each test
                for test_case in collection_doc["testcases"]:
                    if api_datatype.lower() == "json":
                        result = run_tests(test_case, new_endpoint, headers, collection_id, tenant_env_name)
                        if "error" in result:
                            # status = "Failed"
                            break
                        results.append(result)
                        print(results)
                    else:
                        result = run_tests_xml(test_case, new_endpoint, headers, xml_input_field, collection_id,
                                               tenant_env_name)
                        if "error" in result:
                            # status = "Failed"
                            break
                        results.append(result)
                        print(results)
                if results != [] and len(results) == len(collection_doc["testcases"]):
                    for result in results:
                        if result["result"] == "Failed":  # Correct the condition to check if any result is "Failed"
                            status = "Failed"
                            break  # No need to check further if one test has already failed
                    else:
                        status = "Passed"
                elif results == [] or len(results) != len(collection_doc["testcases"]):
                    status = ""

            except Exception as e:
                print("An unexpected error occurred while running testcases:", e)
                status = ""
            if status != "":
                # Insert test results into the 'apitestresults' collection in MongoDB
                try:
                    record = {
                        'collectionId': collection_id,
                        'createdAt': datetime.datetime.now(timezone.utc),
                        'results': results,
                        'status': status,
                        'selectedEnvId': tenant_env_name,
                        'source': source,
                        'source_Id': source_Id
                    }
                    db['apitestresults'].insert_one(record)

                    print('Test Execution Done!!!!!')

                    # updating intermediate data
                    print("Updating Intermediate Data for Stats Calculation!!!")
                    update_intermediate_data(child_dict=record)
                    print("Data updation done!!!")

                except Exception as e:
                    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    logging.error(
                        f"{timestamp} - error occurred while inserting testcases results into collection: {e}")
                    print("An unexpected error occurred while inserting testcases results into collection:", e)



            # print(results)

        else:
            status = "Failed"
            # Insert test results into the 'apitestresults' collection in MongoDB
            try:
                record = {
                    'collectionId': collection_id,
                    'createdAt': datetime.datetime.now(timezone.utc),
                    'results': [],
                    'status': status,
                    'selectedEnvId': tenant_env_name,
                    'failedReason': failedReason,
                    'source': source,
                    'sourceId': source_Id
                }
                db['apitestresults'].insert_one(record)

                print('Test Execution Failed!!!!!')

                # updating intermediate data
                print("Updating Intermediate Data for Stats Calculation when Test Execution Failed!!!")
                update_intermediate_data(child_dict=record)
                print("Data updation done!!!")
            except Exception as e:
                timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                logging.error(f"{timestamp} - error occurred while inserting testcases results into collection: {e}")
                print("An unexpected error occurred while inserting testcases results into collection:", e)

    # Return a response indicating the success of the test execution
    return {
        'status': True
    }


##Endpoint for Swagger and OpenAPI

def resolve_ref(ref, definitions, components):
    """Resolves a JSON reference ($ref) in the Swagger/OpenAPI definitions or components."""
    ref_path = ref.split('/')
    if ref_path[0] != '#':
        return None
    if ref_path[1] == 'definitions':
        def_name = ref_path[2]
        return definitions.get(def_name, {})
    elif ref_path[1] == 'components' and ref_path[2] == 'schemas':
        schema_name = ref_path[3]
        return components.get(schema_name, {})
    return None


def extract_properties(schema, definitions, components):
    """Extracts properties from a schema, resolving references if necessary."""
    properties = {}
    if schema is None:
        return properties

    if "$ref" in schema:
        resolved_ref = resolve_ref(schema["$ref"], definitions, components)
        properties.update(extract_properties(resolved_ref, definitions, components))
    elif "properties" in schema:
        for prop_name, prop_schema in schema["properties"].items():
            if "$ref" in prop_schema:
                resolved_ref = resolve_ref(prop_schema["$ref"], definitions, components)
                properties[prop_name] = extract_properties(resolved_ref, definitions, components)
            else:
                properties[prop_name] = prop_schema
    return properties


def extract_endpoints(swagger_json):
    swagger = json.loads(swagger_json)
    host = swagger.get('host', '')
    base_path = swagger.get('basePath', '')
    schemes = swagger.get('schemes', ['https'])
    base_url = f"{schemes[0]}://{host}{base_path}"

    definitions = swagger.get('definitions', {})
    components = swagger.get('components', {}).get('schemas', {})
    responses = swagger.get('components', {}).get('responses', {})
    api_definitions = []

    for path, path_item in swagger.get('paths', {}).items():
        for method, method_item in path_item.items():
            api_def = {
                "name": method_item.get("summary", ""),
                "description": method_item.get("description", ""),
                "endpoint": f"{base_url}{path}",
                "method": method.upper(),
                "requestParameters": [],
                "response": {},
                "notes": method_item.get("notes", "")
            }

            for param in method_item.get("parameters", []):
                api_def["requestParameters"].append({
                    "name": param.get("name", ""),
                    "type": param.get("type", ""),
                    "required": param.get("required", False),
                    "description": param.get("description", "")
                })

            for response_code, response in method_item.get("responses", {}).items():
                response_body = response.get("schema", {})
                if "$ref" in response_body:
                    resolved_ref = resolve_ref(response_body["$ref"], definitions, components)
                    if resolved_ref is not None:
                        response_properties = extract_properties(resolved_ref, definitions, components)
                        description = response.get("description", "")
                    else:
                        response_properties = {}
                        description = ""
                elif "properties" in response_body:
                    response_properties = extract_properties(response_body, definitions, components)
                    description = response.get("description", "")
                else:
                    response_properties = {}
                    description = response.get("description", "")

                if response_code == '200':
                    api_def["response"][response_code] = {
                        "description": description,
                        "body": response_properties
                    }
                else:
                    api_def["response"][response_code] = {
                        "description": description
                    }

            # Handle default response
            default_response_ref = method_item.get("responses", {}).get("default", {}).get("schema", {}).get("$ref")
            if default_response_ref:
                resolved_ref = resolve_ref(default_response_ref, definitions, components)
                if resolved_ref is not None:
                    response_properties = extract_properties(resolved_ref, definitions, components)
                    description = response.get("description", "")
                else:
                    response_properties = {}
                    description = ""
                api_def["response"]["default"] = {
                    "description": description,
                    "body": response_properties
                }

            api_definitions.append(api_def)

    return api_definitions


@app.route('/v1/generate_api_def', methods=['POST'])
def generate_api_def():
    # Extract data from the incoming JSON request
    data = request.get_json()
    collection_id = data.get('collection_id', '')

    # Connect to MongoDB and retrieve the collection data
    db = client["airegression"]
    collections = db["apiimport"]

    try:
        cursor = collections.find({"_id": ObjectId(collection_id)})
        doc = 0
        for document in cursor:
            doc = document
        print(doc)

    except Exception as e:
        print("An unexpected error occurred while fetching the doc in mongo collection:", e)
        doc = {}

    # Extract functional definition and API definition from the retrieved document
    try:
        openapi_definition = f"""{doc['input_api_definitions']}"""
    except Exception as e:
        print("An unexpected error occurred while extracting funct_def and api_def from doc:", e)
        openapi_definition = """ """

    api_definitions = []
    failedReason = ""
    try:
        api_definitions = extract_endpoints(openapi_definition)
    except Exception as e:
        print("An unexpected error occurred while converting the api_def:", e)
        failedReason = "Json decode error:Invalid or empty api_def provided"

    print(len(api_definitions))

    # Update MongoDB with the generated test cases and endpoint URL
    status = False
    try:
        collections.update_one({"_id": ObjectId(collection_id)}, {
            '$set': {
                "output_api_definitions": api_definitions,
                'updatedAt': datetime.datetime.now(),
                'failedReason': failedReason
            }
        })
        status = True
    except Exception as e:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        logging.error(f"{timestamp} - error occurred while updating the collection with api_def: {e}")
        print("An unexpected error occurred while updating the collection with api_def:", e)
        collections.update_one({"_id": ObjectId(collection_id)}, {
            '$set': {
                'updatedAt': datetime.datetime.now(),
                'failedReason': "error"
            }
        })

    return {
        'status': status
    }


# api mock services
# customer purchase api
purchase_data = {
    "customer1": {
        "2023-11-01": {"productsBought": 3, "totalSpent": 150.00},
        "2023-11-05": {"productsBought": 5, "totalSpent": 250.75},
        "2023-11-20": {"productsBought": 4, "totalSpent": 200.30}
    },
    "customer2": {
        "2023-11-03": {"productsBought": 2, "totalSpent": 76.25},
        "2023-11-12": {"productsBought": 2, "totalSpent": 75.50}
    },
    "customer3": {
        "2023-11-07": {"productsBought": 1, "totalSpent": 30.20},
        "2023-11-18": {"productsBought": 2, "totalSpent": 90.60}
    },
    "customer4": {
        "2023-11-10": {"productsBought": 4, "totalSpent": 180.90},
        "2023-11-22": {"productsBought": 3, "totalSpent": 140.25}
    },
    "customer5": {
        "2023-11-15": {"productsBought": 3, "totalSpent": 120.40}
    }
}


@app.route('/v1/api/customer-purchase', methods=['GET', 'POST'])
def get_customer_purchase_info():
    try:
        # customer_id = request.args.get('customerID')
        # date = request.args.get('date')

        data = request.get_json()

        customer_id = data['customerID']
        date = data['date']

        # Basic validation
        if not (customer_id and date):
            return jsonify({'status': 'error', 'message': 'Invalid input data'}), 400

        # Check if customer and date exist in mocked data
        if customer_id in purchase_data and date in purchase_data[customer_id]:
            return jsonify({
                'status': 'success',
                'message': 'Purchase information found.',
                'productsBought': purchase_data[customer_id][date]['productsBought'],
                'totalSpent': purchase_data[customer_id][date]['totalSpent']
            }), 200
        else:
            return jsonify({'status': 'error',
                            'message': 'Purchase information not found for the specified customer and date.'}), 400

    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500


# mortgage affordability calculator api
@app.route('/v1/api/mortgage-affordability', methods=['GET', 'POST'])
def mortgage_affordability():
    try:
        # Extracting input parameters from the request
        income = float(request.json['income'])
        expenses = float(request.json['expenses'])
        desired_monthly_payment = float(request.json['desiredMonthlyPayment'])
        interest_rate = float(request.json['interestRate'])
        loan_term = int(request.json['loanTerm'])

        # Calculate maximum affordable mortgage amount
        monthly_income_after_expenses = income - expenses
        monthly_interest_rate = interest_rate / 100 / 12
        total_payments = loan_term * 12
        max_affordable_mortgage = (monthly_income_after_expenses / monthly_interest_rate) * \
                                  (1 - (1 + monthly_interest_rate) ** -total_payments)

        # Calculate monthly payment
        monthly_payment = max_affordable_mortgage * monthly_interest_rate / (
                1 - (1 + monthly_interest_rate) ** -total_payments)

        # Prepare response
        response = {
            'maxAffordableMortgage': round(max_affordable_mortgage, 2),
            'monthlyPayment': round(monthly_payment, 2)
        }

        return jsonify(response)

    except Exception as e:
        # Handle invalid input or any other exception
        return jsonify({'error': str(e)}), 400


# Endpoint for generating testcases for chained apis

app.route('/v1/generate_testcases_chained', methods=['GET', 'POST'])(generate_testcases_chained)

# Endpoint for running testcases for chained apis

app.route('/v1/run_testcases_chained', methods=['GET', 'POST'])(run_testcases_chained)


if __name__ == '__main__':
    app.run(debug=True, host="0.0.0.0")

# pip install openai==1.2.0